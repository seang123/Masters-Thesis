---
 # Name the current run
 run: show_and_tell_baseline

 info: | 
     using learning rate schedule
     show and tell model
     trained on subj 2 samples
     standard lstm
     adap grad clip

 attention_loss: False

 # Data stores
 dataset:
     betas_path: "/fast/seagie/data/subj_2/betas_averaged/"
     captions_path: "/fast/seagie/data/subj_2/captions/"
     vgg16_path: "/fast/seagie/data/subj_2/vgg16/"
     nsd_dir: "/home/seagie/NSD2"
 log: "./Log/"

 seed: 42

 # Training
 epochs: 50
 batch_size: 64
 max_length: 13
 optimizer: Adam
 alpha: 0.0001
 clipnorm: 0.1
 decay: 0 #1.0e-4

 dropout_input: 0 # 0.1 #0.1 # 0.17
 dropout_features: 0 # 0.2 #0.33 # 0.18
 dropout_text: 0 #0.2 # 0.25 # 0.01
 dropout_lstm: 0 # 0.2 # 0.5
 dropout_attn: 0 # 0.2 #0.25

 input_reg: 0.01 # 0.002         # scientific notation requires decimal notation - x.0e
 attn_reg: 0.01
 lstm_reg: 0.00003 # 0.0003 
 output_reg: 0.00001 # 1.3e-5

 # Input size
 input: 
     full: 327684
     vc: 62756
     pca: 5000
     mscoco: 4096

 # Model size 
 units: 512 # lstm
 attn_units: 32
 group_size: 32 # acts as embedding dim for attention model
 embedding_features: 512
 embedding_text: 512
 top_k: 5000





